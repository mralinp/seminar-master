\documentclass[12pt,a4paper]{article}
\usepackage{amsthm,amssymb,amsmath}
\usepackage[top=50mm, bottom=50mm, left=50mm, right=50mm]{geometry}

\usepackage{graphicx}
\usepackage[pagebackref=false,colorlinks,linkcolor=blue,citecolor=magenta]{hyperref}
%\usepackage[pagebackref=false]{hyperref}
\usepackage{tocbibind}
\usepackage{makeidx}
\makeindex
\usepackage{xepersian}
\settextfont[Scale=1.1]{XB Niloofar}
% Latex 2020 2021 SetDigitFont error
\ExplSyntaxOn
\cs_set_eq:NN
\etex_iffontchar:D
\tex_iffontchar:D
\cs_undefine:N \c_one
\int_const:Nn \c_one { 1 }
\ExplSyntaxOff
\setdigitfont{Yas}
\defpersianfont\titr[Scale=1]{XB Titre}
\defpersianfont\nastaliq[Scale=1.5]{IranNastaliq}
\defpersianfont\traffic[Scale=1]{B Traffic}

\theoremstyle{definition}
\newtheorem{definition}{تعریف}[section]
\theoremstyle{theorem}
\newtheorem{theorem}[definition]{قضیه}
\newtheorem{lemma}[definition]{لم}
\newtheorem{proposition}[definition]{گزاره}
\newtheorem{corollary}[definition]{نتیجه}
\newtheorem{remark}[definition]{ملاحظه}
\theoremstyle{definition}
\newtheorem{example}[definition]{مثال}

\begin{document}
	\pagenumbering{harfi}
	\thispagestyle{empty}
	\vspace*{-25mm}
	\centerline{\includegraphics[height=4cm]{./images/logos/iust.png}}

	\begin{center}
	\textbf{
		دانشکده مهندسی کامپیوتر
	}
	\\[1cm]
	\baselineskip=2cm
	{\titr
	\begin{Huge}
	تشخیص ناهنجاری با استفاده از شبکه‌های عمیق\\[1cm]
	\end{Huge}}
	{\Large 
		\textbf{
			گزارش سمینار کارشناسی ارشد\\
			در رشته مهندسی کامپیوتر-گرایش هوش مصنوعی
		} \\[1cm]
	}

	{\Large {\traffic 
	نام دانشجو:
	}
	\\[.5cm]
	{\Large \nastaliq علی نادری پاریزی }
	\\
	{\Large\traffic  
		استاد راهنما:
	}}
	\\
	{\Large \nastaliq دکتر محسن سریانی}
	\\[.6cm]
	آبان ماه ۱۴۰۰
	\end{center}

	\newpage
		\begin{center}
		\includegraphics[scale=1]{./images/logos/in-the-name-of-god.jpeg}
		\end{center}
	\newpage

	\section*{چکیده}
	مسئله تشخیص ناهنجاری یکی از مهمترین مسائل مورد مطالعه و پر‌کاربرد در حوزه‌های گوناگون است.
	در علم داده اصطلاح ناهنجاری به داده‌ای تعلق می‌گیرد از نقطه‌نظر یک معیار
	تشابه مشخص میزان تشابه آن با سایر دادگان موجود بسیار کم باشد.
	برای مثال اگر عکس رادیولوژی فردی که بیماری ریوی دارد را با عکس‌های رادیولوژی گرفته شده از ریه افراد سالم مقایسه کنیم متوجه تفاوت
	این عکس با سایر عکس‌ها خواهیم شد. این عدم تشابه در دادگان، مشخص می‌کند  که فرد دچار بیماری ریوی است. درواقع پزشکان با مشاهده این عدم شباهت‌ها به
	وجود بیماری پی می‌برند. عمل مقایسه دادگان می‌تواند به وسیله کامپیوتر نیز انجام شود که موضوع این سمینار است.\\

	در این سمینار قصد داریم به بررسی روش‌های موجود برای تشخیص ناهنجاری بپردازیم که از شبکه‌های عمیق استفاده می‌کنند.
	با توجه به اینکه کاربر‌دهای تشخیص ناهنجاری بسیار متنوع است، روش‌های بررسی شده با تمرکز بر کاربرد پردازش تصویر انتخاب شده‌اند.

	\textit{واژه های کلیدی:}
	ناهنجاری،  شبکه‌های عمیق،  پردازش تصاویر.

	\newpage
	\baselineskip=1cm
	\tableofcontents
	\newpage
	\baselineskip=.75cm
	\pagenumbering{arabic}

	\section{مقدمه}

   تشخیص ناهنجاری‌\footnote{\lr{Anomaly detection}} مسئله مهمی است که در زمینه‌های تحقیقاتی گوناگون مورد مطالعه قرار می‌گیرد و کاربرد‌های بسیار زیادی دارد. در واقع ناهنجاری به دادگانی گفته می‌شود که با توزیع دادگان معمول همخوانی ندارند. این دادگان حقایقی از داده را آشکار می‌کنند که قبلا ناشناخته بودند. به همین دلیل اطلاعات ارزشمندی از دادگان را بدست می‌دهند که می‌توان از آنها برای تصمیم‌گیری‌ استفاده کرد.\\

در کنار ناهنجاری‌ها، دادگان دیگری نیز وجود دارند که با دادگان عادی متفاوت‌اند امّا این تفاوت به اندازی کافی زیاد نیست. به این دادگان اصطلاحا دادگان نوین\footnote{\lr{Novelties}} گفته می‌شود. دادگان نوین درواقع دادگانی هستند که در دسته دادگان عادی قرار می‌گیرند اما چون هنوز کشف نشده اند به نظر می‌رسد که با دادگان عادی تفاوت داشته باشند. برای مثال، اکثر ببر‌های دیده شده و شناخته شده به رنگ نارنجی و با خطوط راه راه سیاه بوده اند و دیدن بربر سفید برای ما تعجب آور خواهد بود. امّا همه به خوبی می‌دانیم که ببر سفید درواقع یک ببر است که فقط رنگ آن غیرعادی است و نباید آن را در دسته جدایی از حیوانات قرار داد. \\

در اکثر روش‌های ارائه شده برای تشخیص ناهنجاری اقدام به بدست آوردن یک امتیاز برای ناهنجاری\footnote{\lr{Anomaly score}} می‌کنند. این امتیاز به طریقی می‌تواند نشان‌‌دهنده احتمال تعلق این داده به دسته ناهنجاری‌ها باشد. ساده‌ترین روش برای تصمیم‌گیری در مورد یک داده قرار دادن یک مقدار آستانه برای امتیاز ناهنجاری است. اگر امتیاز داده شده به داده از مقدار آستانی بیشتر بود، داده به دسته ناهنجاری‌ها تعلق خواهد گرفت و در غیر این صورت نمی‌توان آن‌را به دسته ناهنجاری‌ها انتصاب داد.\\

اکثر روش‌های مورد استفاده برای پیدا کردن ناهنجاری‌ها در دادگان از روش‌های سنتی استفاده می‌کنند که به مراتب دارای ایراداتی هستند. با توجه به اینکه امروزه استفاده از شبکه‌های عمیق در حل مسائل رونق یافته،‌می‌توان برای حل مسئله یافتن ناهنجاری‌‌ها نیز مورد استفاده قرار گیرند. در این سمینار سعی شده روش‌های استفاده شده برای تشخیص ناهنجاری که از شبکه‌های عمیق استفاده میکنند را مورد بررسی قرار دهیم و ضمن معرفی انواع روش‌ها یک دسته بندی متناسب با کاربرد برای این روش‌ها نیز ارائه دهیم. با توجه به گستردگی کاربرد این حوزه، بیشتر روش‌های مورد استفاده در پردازش تصویر و بینایی کامپیوتر مورد بحث قرار خواهند گرفت.
	\subsection{معرفی حوزه سمینار}
در این سمینار تلاش شده روش‌های مبتنی بر یادگیری عمیق در حوزه تشخیص ناهنجاری را برسی کنیم. از آنجا که این حوزه در رشته‌های بسیار زیادی استفاده دارد و مقالات بسیار متعددی بسته به کاربرد در حوزه‌های گوناگون به چاپ رسیده است، سعی کردیم حوزه سمینار را محدود کرده و ضمن معرفی انواع کاربرد‌های مسئله تشخیص ناهنجاری به بررسی روش‌هایی بپردازیم که در رابطه با کاربرد پردازش تصویر و بینایی کامپیوتر هستند. با توجه به تعدد مقالات در سال‌های اخیر و وجود مقالات جامع در این حوزه سعی کردیم بیشتر مقالات جدید که در سنوات ۲۰۱۹ به بعد منتشر شده اند را بررسی کرده و برای باقی روش‌ها به ارجاع دهی به مقالات دیگر اکتفا کنیم.\\

در این سمینار ابتدا یک دسته بندی کلی از روش‌های مختلف شبکه‌های عمیق ارائه کرده و سپس به بررسی روش‌های جدید که در این دسته‌بندی می‌گنجند می‌پردازیم.
در بررسی روش‌ها به کاربرد روش و مسائل قابل حل،‌پیچیدگی، قابلیت پیاده سازی صنعتی،‌نحوه آموزش و دادگان مورد نیاز خواهیم پرداخت.
	\subsection{ساختار گزارش}
در فصل اوّل این سمینار به معرفی حوزه سمینار و تعریف مسئله پرداخته شد و در فصل دوّم به تعریف مفاهیم و اصطلاحات استفاده شده در این حوزه خواهیم پرداخت. فصل سوّم نیز در رابطه با بررسی کار‌های مرتبط با این سمینار و معرفی و بررسی جزئی از روش‌ها و مقالات موجود چاپ شده در سال‌های اخیر خواهد پرداخت. در ابتدای فصل سوّم پس از معرفی کار‌های مرتبط یک دسته‌بندی از روش‌های موجود ارائه می‌گردد و در ادامه، ترتیب معرفی و بررسی روش‌های موجود بر طبق این دسته‌بندی خواهد بود. در نهایت یک جمع بندی و نتیجه گیری کلی از روش‌های موجود در هر دسته انجام می‌دهیم و پیشنهاداتمان را در رابطه با استفاده از این روش‌ها بسته به کاربرد مورد نظر ارائه می‌کنیم. در فصل آخر گزارش پیشنهادات خود را درباره کار‌های آینده این حوزه ارائه کرده و در نهایت پیشنهاد انجام پروژه کارشناسی ارشد را که در راستای همین سمینار است معرفی می‌کنیم.
	\section{تعاریف و مفاهیم مبنایی}
		\definition{یادگیری ماشین\footnote{\lr{Machine Learning}}}
		یک حوزه مطالعاتی است که در آن تمرکز بر تولید روش‌ها و الگوریتم‌هایی است که باعث شوند ماشین چیزی را یاد بگیرد.
		\definition{تشخیص ناهنجاری\footnote{\lr{Anomaly Detection}}}
		در یادگیری ماشین به عملیات تشخیص نقاط، رویدادها و یا مشاهداتی که با توزیع دادگان معمول تفاوت دارند گفته می‌شود.
		\definition{یادگیری با ناظر\footnote{\lr{Supervised learning}}}
در یادگیری ماشین هنگامی که در فرایند یادگیری دادگان برچسب خورده در اختیار داشته باشیم و یا با استفاده از یک ناظر جواب مسئله را برای هر داده بتوانیم بدست آوریم عمل یادگیری اصطلاحا یادگیری با ناظر خوانده می‌شود.
		\definition{یادگیری با نظارت ضعیف\footnote{\lr{Semi-supervised learning}}}
به عمل یادگیری گفته میشود که عمل برچسب زنی بر روی دادگان به صورت کامل انجام نگرفته است و یا بخشی از دادگان بدون برچسب صحیح در اختیار هستند.
		\definition{یادگیری بدون ناظر\footnote{\lr{Unsupervised learning}}}
نوعی از یادگیری است که در آن هیچ گونه اطلاعی از دسته بندی و یا جواب صحیح دادگان در دسترس نمی‌باشد. در این نوع از یادگیری دادگان در دسترس میتوانند به فراوانی جمع آوری شوند اما بنا به دلایلی مانند مشکل بودن فرایند برچسب زنی، برچسب دادگان در دسترس ماشین یادگیرنده قرار ندارد.
		\definition{شبکه‌های عصبی\footnote{\lr{Neural networks}}}
یک روش محاسباتی جدید است که ساختار شبکه‌ای دارد و با دریافت داده ورودی به محاسبه خروجی می‌پردازد.
		\definition{شبکه های عصبی عمیق\footnote{\lr{Deep neural networks}}}
نوعی از شبکه‌های عصبی هستند که دارای تعداد لایه‌های بیشتر از ۲ لایه هستند. این شبکه‌ها قابلیت ظرفیت یادگیری بسیار بالایی هستند و با گرفتن داده ورودی قادراند برای حل مسئله داده شده ویژگی‌های مناسب برای حل مسئله را نیز کشف کنند.
		\definition{یادگیری عمیق\footnote{\lr{Deep learning}}}
عمل یادگیری با استفاده از شبکه‌های عمیق را گویند.
		\definition{مجموعه دادگان\footnote{\lr{Dataset}}}
به مجموعه دادگان در دسترس برای انجام فرآیند یادگیری گفته میشود.
		\definition{یادگیری تقویتی\footnote{\lr{Reinforcement learning}}}
نوعی عمل یادگیری است که در آن عامل(ماشین) با محیط خود در ارتباط است و با استفاده از پاسخ‌هایی که از محیط دریافت می‌کند اقدام به یادگیری یک عمل می‌کند.
		
	\section{مروری بر کار‌های مرتبط}
	\subsection{مقدمه}
	\subsection{عنوان بخش}
	\subsubsection{توضیح بخش}
	\subsection{مقایسه و نتیجه گیری}
	\section{نتیجه گیری و کار‌های آینده}
	\subsection{مقدمه}
	\subsection{نتیجه گیری}
	\subsection{مسائل باز و کارهای قابل انجام}
	\subsection{موضوع پیشنهادی برای پایان نامه}
	\newpage
	
	\small
%دستوری برای ظاهر شدن کلمه«مراجع» در فهرست مطالب
%\addcontentsline{toc}{section}{مراجع}
%ایجاد «مراجع»
\begin{thebibliography}{99}

\begin{LTRitems}

\resetlatinfont

\bibitem{R. Chalapathy}
R. Chalapathy, C. Chawla, {\em Deep learning for anomalu detection: a survay},  arXive, 2019.

\bibitem{aliprantis}
C.D. Aliprantis and O. Burkinshaw,   {\em Principles of Real Analysis}.  Academic Press.  1998,  xii+415 pp.

\bibitem{Alvarez1}
M. Alvarez-Manilla, {\em Measure theoretic results for continuous valuations on partially ordered
spaces}, Dissertation, Imperial College, London, 2000.

\bibitem{Alvarez2}
M. Alvarez-Manilla, {\em Extension of valuations on locally compact sober spaces}, Topology and its
Applications, 124, 2002 397-433.

\bibitem{Billingsley}
P. Billingsley, {\em Probability and Measure}, 2nd Edition, John Wiley \& Sons, 1986.

\bibitem{D.A. Edwards}
D.A. Edwards, {\em On the existence of probability measures with given marginals}, Annales de
l’Institut Fourier, Grenoble 28 1978, 53–78.

\bibitem{G. Gierz}
G. Gierz, K.H. Hofmann, K. Keimel, J.D. Lawson, M. Mislove, and D.S. Scott. {\em Continuous
Lattices and Domains}, Encyclopedia of Mathematics and its Applications 93, Cambridge
University Press, 2003, xxxvi+591pp.

\bibitem{Halmos}
P. Halmos, {\em Measure Theory}, D. Van-Nostrand Company, 1950.

\bibitem{Jones}
C. Jones,  {\em Probabilistic Non-Determinism}. PhD thesis, University of Edinburgh, Edinburgh,
1990. Also published as Technical Report No. CST-63-90.

\bibitem{Jung}
A. Jung,  {\em Cartesian Closed Categories of Domains}, volume 66 of CWI Tracts. Centrum voor
Wiskunde en Informatica, Amsterdam, 1989, 107 pp.

\bibitem{Kegelmann}
A. Jung, M. Kegelmann, and M.A. Moshier,  {\em Multi lingual sequent calculus and coherent spaces}.
Electronic Notes in Theoretical Computer Science, 6, 1997.

\bibitem{main}
K. Keimel, {\em The Probabilistic Powerdomain for Stably Compact Spaces via Compact Ordered Spaces}, Electronic Notes in Theoretical Computer Science 87, 2004 225–238.

\bibitem{Jung and Tix}
A. Jung and R. Tix,  {\em The troublesome probabilistic powerdomain}. Electronic Notes in
Theoretical Computer Science, 13, 1998.

\bibitem{Konig}
H. K¨onig,  {\em Measure and Integration}, Springer–Verlag, 1997, xxi+260 pp.

\bibitem{lawson}
J.D. Lawson, {\em Valuations on continuous lattices}. In: Math. Arbeitspapiere 27, Univ. Bremen,
1982, Ed. R.-E. Hoffmann, 204–225.

\bibitem{lawson 2}
J.D. Lawson, {\em Domains, Integration, and Positive Analysis}. Mathematical Structures in
Computer Science, 14, 2004, 815-832.

\bibitem{Nachbin}
L. Nachbin, {\em Topology and Order}. Van-Nostrand, Princeton, N.J., 1965.

\bibitem{rudin} 
W. Rudin,  {\em Real and Complex Analysis}.  Mc Graw-Hill Book Comp. 1966, xi+412 pp.

\bibitem{functional}
W. Rudin,  {\em Functional Analysis},  2nd Edition, Mc Graw-Hill Book Comp.  1991,  xv+424.

\bibitem{Tix} 
R. Tix,  {\em Stetige Bewertungen auf topologischen R¨aumen}. Diplomarbeit, Technische Universit¨at
Darmstadt, June 1995, 51 pp.

\end{LTRitems}

\end{thebibliography}

%\addcontentsline{toc}{section}{نمایه}
%دستوری برای ظاهر شدن کلمه «نمایه» در فهرست مطالب(البته در صورتی که از بسته‌ای که در ابتدا گفته شد استفاده نکرده باشید)
%ایجاد «نمایه»
\printindex


\end{document}
