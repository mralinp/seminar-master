\documentclass[12pt,a4paper]{report}
\usepackage{amsthm,amssymb,amsmath}
\usepackage[top=50mm, bottom=50mm, left=50mm, right=50mm]{geometry}

\usepackage{graphicx}
\usepackage{subcaption}
\usepackage[pagebackref=false,colorlinks,linkcolor=blue,citecolor=magenta]{hyperref}


\usepackage{geometry}
\usepackage{datetime} 
\usepackage{multirow}


\newcommand*{\BeginNoToc}{%
  \addtocontents{toc}{%
    \edef\protect\SavedTocDepth{\protect\the\protect\value{tocdepth}}%
  }%
  \addtocontents{toc}{%
    \protect\setcounter{tocdepth}{-10}%
  }%
}
\newcommand*{\EndNoToc}{%
  \addtocontents{toc}{%
    \protect\setcounter{tocdepth}{\protect\SavedTocDepth}%
  }%
}
\renewcommand{\bibname}{مراجع}
%\renewcommand{\refname}{مراجع}

%\usepackage[pagebackref=false]{hyperref}
\usepackage{tocbibind}
\usepackage{makeidx}
\makeindex
\usepackage{xepersian}
\settextfont[Scale=1.1]{B Nazanin}
% Latex 2020 2021 SetDigitFont error
\ExplSyntaxOn
\cs_set_eq:NN
\etex_iffontchar:D
\tex_iffontchar:D
\cs_undefine:N \c_one
\int_const:Nn \c_one { 1 }
\ExplSyntaxOff
\setdigitfont{Yas}
\defpersianfont\titr[Scale=1]{XB Titre}
\defpersianfont\nastaliq[Scale=1.5]{IranNastaliq}
\defpersianfont\traffic[Scale=1]{B Traffic}


\theoremstyle{definition}
\newtheorem{definition}{تعریف}[section]
\newtheorem{theorem}[definition]{قضیه}
\newtheorem{lemma}[definition]{لم}
\newtheorem{proposition}[definition]{گزاره}
\newtheorem{corollary}[definition]{نتیجه}
\newtheorem{remark}[definition]{ملاحظه}
\theoremstyle{definition}
\newtheorem{example}[definition]{مثال}


\begin{document}
	\newgeometry{total={210mm,297mm}, left=40mm, right=40mm, top=20mm, bottom=20mm,}
	\pagenumbering{harfi}
	\thispagestyle{empty}
	\vspace*{25mm}
	\centerline{\includegraphics[height=4cm]{./images/logos/iust.png}}

	\begin{center}
	\textbf{
		دانشکده مهندسی کامپیوتر
	}
	\\[1cm]
	\baselineskip=2cm
	{\titr
	\begin{Huge}
	تشخیص ناهنجاری با استفاده از شبکه‌های عمیق\\[1cm]
	\end{Huge}}
	{\Large 
		\textbf{
			گزارش سمینار کارشناسی ارشد\\
			در رشته مهندسی کامپیوتر-گرایش هوش مصنوعی و رباتیک
		} \\[1cm]
	}

	{\Large { 
	نام دانشجو:
	}
	\\
	{\Large  علی نادری پاریزی }
	\\[.5cm]
	{\Large  
		استاد راهنما:
	}
	\\
	{\Large دکتر محسن سریانی}
	\\[.6cm]
	}
	اردیبهشت ماه ۱۴۰۱
	\end{center}

	\newpage
		\begin{center}
		\includegraphics[scale=1]{./images/god.png}
		\end{center}
	\newpage
	
	\newgeometry{total={210mm,297mm}, left=20mm, right=20mm, top=20mm, bottom=20mm,}
	
	\chapter*{چکیده}
	تشخیص ناهنجاری‌ مسئله مهمی است که در زمینه‌های تحقیقاتی گوناگون مورد مطالعه قرار می‌گیرد و کاربرد‌های بسیار زیادی دارد. یک نیاز مرسوم در حوزه تجزیه و تحلیل داده‌های دنیای واقعی، پی بردن به این است که بدانیم کدام نمونه‌ها از نقطه نظر تشابه رفتار و ظاهر با اکثریت نمونه‌های موجود بسیار متفاوت هستند. این تفاوت می‌تواند به دلیل خطای انداز‌ه‌گیری در هنگام جمع آوری داده‌ها باشد. گاهی اوقات این تفاوت می‌توانند نشان‌ دهنده وجود پدیده‌ای ناشناخته‌ باشد که در پشت‌پرده جامعه آماری مورد مطاالعه در حال رخ دادن است و ما از آن بی‌خبر هستیم. \\
در علم داده اصطلاح ناهنجاری به داده‌ای تعلق می‌گیرد از نقطه‌نظر یک معیار تشابه تعریف شده، میزان تشابه آن با سایر دادگان موجود بسیار کم باشد. برای مثال اگر عکس رادیولوژی فردی که بیماری ریوی دارد را با عکس‌های رادیولوژی گرفته شده از ریه افراد سالم مقایسه کنیم متوجه تفاوت این عکس با سایر عکس‌ها خواهیم شد. این عدم تشابه در دادگان، مشخص می‌کند  که فرد دچار بیماری ریوی است. درواقع پزشکان با مشاهده این عدم شباهت‌ها به وجود بیماری پی می‌برند. عمل مقایسه دادگان می‌تواند به وسیله کامپیوتر نیز انجام شود که موضوع این سمینار است.\\

در این سمینار تلاش شده روش‌های مبتنی بر یادگیری عمیق برای تشخیص ناهنجاری را برسی کنیم. از آنجا که کاربرد این موضوع در حوزه‌های گوناگون بسیار وسیع است و مقالات بسیار متعددی در رابطه با کاربردی‌های مختلف به چاپ رسیده، سعی کردیم حوزه سمینار را محدود کرده و ضمن معرفی انواع کاربرد‌های مسئله تشخیص ناهنجاری، به بررسی روش‌هایی بپردازیم که در رابطه با کاربرد پردازش تصویر و بینایی کامپیوتر هستند. با توجه به تعدد مقالات در سال‌های اخیر و وجود مقالات جامع در این حوزه بیشتر، مقالات جدید که در سال‌های  ۲۰۱۹ میلادی و بعد از آن منتشر شده‌اند را بررسی کنیم و برای باقی روش‌ها به ارجاع دهی به مقالات دیگر اکتفا کنیم.\\

	\textit{
واژه‌های کلیدی:
	}
	تشخیص ناهنجاری، پردازش تصویر، شبکه‌های عمیق

	\newpage
	\baselineskip=1cm
	\BeginNoToc
	\tableofcontents
	\listoffigures
	\listoftables
	\EndNoToc
	
	\newpage
	
	\baselineskip=.75cm
	\pagenumbering{arabic}
	%-------------------Chapter 1-----------------
	\chapter{مقدمه}
	تشخیص ناهنجاری‌\LTRfootnote{\lr{Anomaly detection}} مسئله مهمی است که در زمینه‌های تحقیقاتی گوناگون مورد مطالعه قرار می‌گیرد و کاربرد‌های بسیار زیادی دارد. یک نیاز مرسوم در حوزه تجزیه و تحلیل داده‌های دنیای واقعی، پی بردن این است که بدانیم کدام نمونه‌ها از نقطه نظر تشابه رفتار و ظاهر با اکثریت نمونه‌های موجود بسیار متفاوت هستند. این تفاوت می‌تواند به دلیل خطای انداز‌ه‌گیری در هنگام جمع آوری داده‌ها باشد. گاهی اوقات این تفاوت می‌توانند نشان‌ دهنده وجود پدیده‌ای ناشناخته‌ باشد که در پشت‌پرده جامعه آماری مورد مطاالعه در حال رخ دادن است و ما از آن بی‌خبر هستیم. 
	
	\begin{figure}[hp]
		  \begin{subfigure}{\linewidth}
			  \includegraphics[width=.5\linewidth]{./images/figures/zibra-anomaly.png}\hfill
			  \includegraphics[width=.5\linewidth]{./images/figures/zibra-novel.png}
		  \end{subfigure}\par\medskip		  
		  \caption{مثالی از تفاوت دادگان ناهنجار و نوین}
		  \label{fig:novel-vs-anomaly}
	\end{figure}

در کنار ناهنجاری‌ها، دادگان دیگری نیز وجود دارند که با دادگان عادی متفاوت‌اند امّا این تفاوت به اندازی کافی زیاد نیست. به این دادگان اصطلاحا دادگان نوین\LTRfootnote{\lr{Novelties}} گفته می‌شود. دادگان نوین درواقع دادگانی هستند که در دسته دادگان عادی قرار می‌گیرند اما چون هنوز کشف نشده‌اند به نظر می‌رسد که با دادگان عادی تفاوت داشته باشند. برای مثال، اکثر ببر‌های دیده شده و شناخته شده به رنگ نارنجی و با خطوط راه راه سیاه هستند و دیدن بربر سفید برای ما تعجب آور خواهد بود. امّا همه به خوبی می‌دانیم که ببر سفید درواقع یک ببر است که فقط رنگ آن غیرعادی است و نباید آن را در دسته جدایی از حیوانات قرار داد.\\

در ادامه این فصل پس از تعریف ناهنجاری در دادگان، به بیان کاربرد‌های این بحث در حوزه‌های مختلف می‌پردازیم. سپس یک تعریف معیار که مرتبط با حوزه مورد نظر ما که همان پردازش تصویر است ارائه می‌دهیم. پس از تعریف حوزه مورد مطالعه و بررسی اهمیت موضوع، به توضیح ساختار کلی گزارش این سمینار خواهیم پرداخت.
		
	\section{شرح مسئله}
تشخیص ناهنجاری که با عنوان تشخیص دادگان خارج از محدوده\LTRfootnote{Outlier detection} نیز شناخته می‌شود، به عملیاتی گفته می‌شود که طی آن به آشکارسازی نمونه‌هایی از مجموعه دادگان می‌پردازد که تفاوت زیادی با اکثریت دادگان موجود دارد. در واقع، اینجا تفاوت به معنی متفاوت بودن مشخصات و ویژگی‌های این نمونه‌ها با الگوی معمول موجود در مجموعه دادگان است. این مسئله یک موضوع فعال تحقیق در دهه‌های اخیر بوده که تقریبان از سال ۱۹۶۰ میلادی تا کنون مورد مطالعه قرار گرفته است~\cite{Grubbs1969ProceduresFD}. با توجه به نیاز روز افزون کاربر‌های 

\begin{figure}[hp]
	\begin{center}
		\includegraphics[width=\linewidth]{./images/figures/image-anomaly-examples-1.png}
		\caption*{به ترتیب از سمت چپ، توده سرطان سینه، مین زیر‌دریایی، نقص رنگ‌آمیزی کاشی تولید شده در کارخانه،نمونه نقص موجود در چرخ خودرو.}
		\caption{
		مثال‌هایی از ناهنجاری در تصاویر
		\cite{T.Ehret}
		}		
		\label{fig:anomaly-example-1}
		\centering
	\end{center}
\end{figure}




	\section{معرفی حوزه سمینار}


در این سمینار ابتدا یک دسته بندی کلی از روش‌های مختلف شبکه‌های عمیق ارائه کرده و سپس به بررسی روش‌های جدید که در این دسته‌بندی می‌گنجند می‌پردازیم.
در بررسی روش‌ها به کاربرد روش و مسائل قابل حل،‌پیچیدگی، قابلیت پیاده سازی صنعتی،‌نحوه آموزش و دادگان مورد نیاز خواهیم پرداخت.
	\section{اهمیت موضوع}
	
	\section{ساختار گزارش}
در فصل اوّل این سمینار به معرفی حوزه سمینار و تعریف مسئله پرداخته شد و در فصل دوّم به تعریف مفاهیم و اصطلاحات استفاده شده در این حوزه خواهیم پرداخت. فصل سوّم نیز در رابطه با بررسی کار‌های مرتبط با این سمینار و معرفی و بررسی جزئی از روش‌ها و مقالات موجود چاپ شده در سال‌های اخیر خواهد پرداخت. در ابتدای فصل سوّم پس از معرفی کار‌های مرتبط یک دسته‌بندی از روش‌های موجود ارائه می‌گردد و در ادامه، ترتیب معرفی و بررسی روش‌های موجود بر طبق این دسته‌بندی خواهد بود. در نهایت یک جمع بندی و نتیجه گیری کلی از روش‌های موجود در هر دسته انجام می‌دهیم و پیشنهاداتمان را در رابطه با استفاده از این روش‌ها بسته به کاربرد مورد نظر ارائه می‌کنیم. در فصل آخر گزارش پیشنهادات خود را درباره کار‌های آینده این حوزه ارائه کرده و در نهایت پیشنهاد انجام پروژه کارشناسی ارشد را که در راستای همین سمینار است معرفی می‌کنیم.
	%------------Chapter 2--------------
	\chapter{مروری بر روش‌های سنتی}
	اگر به‌یاد داشته باشید، در ابتدای فصل یک به این نکته اشاره شد که مسئله تشخیص ناهنجاری، یک موضوع فعال تحقیق در چند دهه اخیر است که یکی از مقالات معتبر چاپ شده آن مربوط به دهه ۱۹۶۰ میلادی می‌شود. از این رو، در طی این مدت بسیاری از روش‌ها برای یافتن دادگان خارج از محدوده معرفی و توسعه داده شده‌اند که از یادگیری عمیق استفاده نمی‌کنند. این روش‌ها به صورت عمده دادگان را مجموعه‌ای از نقاط در یک فضای چند بعدی فرض می‌کنند و تلاش آنها برای این است که نقاط خارج از محدوده را در این فضا با توجه به ویژگی‌ها و مشخصات دیگر نقاط آشکار کنند. عمدتاً این اینگونه روش‌ها را می‌توان از نقطه‌نظر ایده اصلی به سه دسته کلی استفاده از رده‌بندی، معیار فاصله و مدل‌های آماری تقسیم کرد\footnote{ر.ک جدول~\ref{table:traditional-category}}. در ادامه به مرور کلی این روش‌ها خواهیم پرداخت. با توجه به اینکه تمرکز ما بر بررسی کامل این روش‌ها نیست پیشنهاد می‌شود برای آشنایی بیشتر با این‌گونه روش‌ها به مقاله چاندولا و همکاران مراجعه کنید~\cite{V.Chandola}.
	
\begin{center}
\begin{table}[!h]
\begin{tabular}{ |p{4cm}|p{4cm}|p{4cm}|p{4cm}| } 
\hline
\multicolumn{4}{|c|}{دسته‌بندی روش‌های سنتی در تشخیص ناهنجاری}  \\
\hline

مبتنی بر ‌ & خلاصه ایده& انواع & روش‌های شناخته شده \\
\hline
رده‌بندی & یادگیری یک مرز تفکیک میان دادگان عادی و ناهنجار & یک کلاسه & \latin{One-class SVM} \latin{SVDD} \\
\cline{3-4}
& & چند کلاسه & - \\

\hline
معیار فاصله & اقدام به تعریف یک معیار فاصله می‌کند تا دادگان عادی را از دادگان ناهنجار جدا کند &  فاصله تا نزدیک ترین همسایه &  \latin{LOC}\LTRfootnote{Local Outlier Factor}  \latin{COF} \\
\cline{3-4}
&&خوشه بندی و سنجش فاصله تا نزدیک ترین خوشه& \latin{K-means} \latin{CBLOF} \\

\cline{3-4}
&&استفاده از تصویر سازی نقاط در فضایی با ابعاد کمتر& \latin{PCA} \latin{Isolation Forest} \\

\hline 
مدل آماری & دادگان عادی در نواحی پر احتمال مدل آماری قرار می‌گیرند & روش‌های پارامتری  & \latin{Gausian Mixture Model} \\
\cline{3-4}
&&روش‌های غیر پارامتری ‌& \latin{Kernel destiny estimator} \\
\hline

\end{tabular}
\caption{دسته‌بندی روش‌های سنتی}
\label{table:traditional-category}
\end{table}
\end{center}
	
	\section{ساختار کلی روش‌های تشخیص ناهنجاری}
	اگر بخواهیم روش‌های تشخیص ناهنجاری را به صورت عمومی توصیف کنیم، می‌توانیم بگوییم که این روش‌ها از سه بخش اصلی تشکیل شده‌اند. بخش اوّل یادگیری بازنمایی داد‌ه‌ها\LTRfootnote{Data representation} است. در این مرحله نگاشتی از دادگان ورودی به فضایی معیین آموخته می‌شود. این نگاشت را می‌توان به صورت تابعی مانند زیر تعریف کرد.
\begin{equation}
f(.;\theta): x \rightarrow y
\end{equation}
	
در بخش دوّم به تعریف یک معیار سنجش پرداخته می‌شود که برای ارزیابی خروجی مرحله قبل استفاده می‌شود. این معیار با دریافت خروجی مرحله اوّل یک امتیاز برای سنجش میزان تعلق داده ورودی به دسته ناهنجار اختصاص می‌دهد که به آن امتیاز ناهنجاری\LTRfootnote{Anomaly score} گوییم.
\begin{equation}
d(f(x);\eta): f(x) \rightarrow d \  ,\  d \in \mathbb{R}
\end{equation}

در آخر نیز با درنظر گرفتن یک مقدار آستانه $\delta$، به تصمیم‌گیری در مورد داده ورودی با توجه به امتیاز اختصاص داده شده در مرحله دوّم پرداخته می‌شود.

$$
\left\{
	\begin{array}{ll}
		anomaly  & d \geq \delta \\
		not\ anomaly & d < \delta
	\end{array}
\right.
$$

با توجه به این تعریف، رویکرد‌های موجود می‌توانند انواع زیر را داشته باشند:
\begin{enumerate}
	\item {غیر پارامتری: نیازی به یادگیری $\theta$ و $\eta$ و $\delta$ نیست.}
	\item{یک مرحله‌ای: تنها یکی از مجموعه پارامترهای موجود $\theta$ یا  $\eta$ یاد‌گرفته می‌شوند.}
	\item{دو مرحله‌ای:‌ هر دو مجموعه پارامتر $\theta$ و $\eta$ به صورت مستقل و جداگانه یاد‌گرفته می‌شوند.}
	\item{ادغامی\LTRfootnote{Integrated}: هر دو مجموعه پارامتر $\theta$ و $\eta$ باهم یادگرفته می‌شوند. }
\end{enumerate}

درصورت عدم وجود برچسب‌های دادگان موجود، ناچار به استفاده از روش بدون ناظر هستیم که در آن از هیچ گونه اطلاعاتی در مورد ماهیت دادگان استفاده نمی‌شود. در  این گونه مواقع معمولا $\delta$ از پیش تعریف شده است و یا همراه با  $\eta$ یادگرفته می‌شود. در حالتی که تنها بخشی از دادگان برچسب خورده باشند و باقی برچسب نخورده، می‌توانیم از رویکرد یادگیری با نظارت ضعیف استفاده کرد. در این مورد نیز مقدار آستانه می‌تواند با استفاده از تنظیم دقیق مدل بدست آید.


\section{روش‌های مبتنی بر رده‌بندی}
همانطور که در ابتدای این بخش گفته شد، یکی از ایده‌های کلی در روش‌های مورد استفاده برای تشخیص ناهنجاری استفاده از ایده رده‌بندی است. در اینگونه روش‌ها تلاش می‌شود یک مرز تفکیک میان دادگان عادی و دادگان ناهنجار رسم شود. اگر چنین مرزی وجود داشته باشد، می‌توانیم با استفاده از الگوریتم‌های رده‌بند موجود اقدام به یافتن این مرز کرد و سپس با استفاده از مدل آموزش دیده اقدام به آشکارسازی داده‌های ناهنجار کرد. همانطور که مشخص است در این گونه روش‌ها تنها یک دسته برای دادگان تعریف می‌شود که آن دسته دادگان عادی است. دیگر دادگانی که در این دسته قرار نمی‌گیرند به عنوان دادگان عادی در نظر گرفته می‌شوند. البته استفاده از رویکرد رده‌بندی چند کلاسه نیز در صورت وجود برچسب برای تمامی دادگان امکان پذیر است امّا استفاده از این روش کمتر مرسوم است. یکی از معروف ترین روش‌های مورد استفاده دسته بند بردار پشتیبان یک کلاسه\LTRfootnote{One-class SVM} است.

در ماشین بردار پشتیبان ما به دنبال یافتن یک ابر صفحه جدا کننده میان دو دسته داده موجود هستیم. در الگوریتم بردار پشتیبان یک کلاسه ما درواقع به دنبال یافتن صفحه ای هستیم که دادگان معمول در یک طرف این صفحه قرار بگیرند. در این روش تلاش می‌شود صفحه مورد نظر تا حد امکان به نقاد داده نزدیک باشند. پس از رسم این صفحه، دادگانی که به مبدا مختصات نزدیک تر هستند در دسته ناهنجاری‌ها قرار می‌گیرند \cite{10.5555/3009657.3009740}.

در اینجا تابع نگاشتی که باید یاد کرفته شود همان تابع کرنل در ماشین بردار پشتیبان است و تابع امتیاز ناهنجاری نیز به صورت اندازه فاصله از مبدا مختصات تعریف می‌شود. شکل~\ref{fig:one-class-svm} این روش را به تصویر کشیده است. توجه داشته باشید که در اینجا تنها یک دسته برای رده‌بندی تعریف می‌شود که آن دسته دادگان عادی است، پس نیازی به وجود برچسب برای تمامی دادگان نیست و رویکرد ما در اینجا به صورت کاملا بدون ناظر خواهد بود.
\begin{figure}[!h]
	\begin{center}
		\includegraphics[width=0.5\linewidth]{./images/figures/one-class-svm.png}
	\end{center}
	\caption{ماشین بردار پشتیبان یک کلاسه}
	\label{fig:one-class-svm}
	\centering
\end{figure}


نمونه دیگری از روش‌های مورد استفاده برای آشکارسازی ناهنجاری که از رویکرد رده‌بندی استفاده می‌کند، بردار پتیبان توصیفگر داده‌\LTRfootnote{Support Vector Data Description (SVDD)} است. در این روش سعی می‌شود کره‌ای با کوچک ترین اندازه ممکن حول دادگان موجور رسم شود. پس از رسم این کره، دادگانی که در خارج از آن قرار می‌گیرند به عنوان داده ناهنجار شناخته خواهند شد~\cite{pmlr-v80-ruff18a} .
\begin{figure}[!h]
	\begin{center}
		\includegraphics[width=\linewidth]{./images/figures/deep-svdd.png}
	\end{center}
	\caption{بردار پشتیبان توصیفگر داده عمیق~\cite{pmlr-v80-ruff18a}}
	\label{fig:deep-svdd}
	\centering
\end{figure}

ازجمله مزیت‌های این رویکرد،‌آموزش سریع، و دقت بهتر آن در مواقعی است که دادگان برچسب خورده در اختیار هستند. و از معایب این روش در هنگام استفاده از رده‌بندی چند کلاسه می‌توان به نیاز برای چندین دسته داده عادی یاد کرد. همچنین این این رویکرد‌ها نیاز به تعیین ابر پارامتر برای مدل یادگیری دارند.

\section{روش‌های مبتنی بر معیار فاصله}
اگر به دادگان موجود را به صورت نقاطی بازنمایی شده بر روی صفحه مختصات نگاه کنیم،‌ می‌توانیم از معیار فاصله نقاط از یکدیگر به تصمیم‌گیری در مورد دادگان بپردازیم. در اینگونه رویکرد‌ها معمولا اقدام به تعریف یک معیار فاصله می‌کنند تا دادگان عادی را از دادگان ناهنجار جدا کنند. یک نمونه روش معروف که در این دسته می‌گنجد روش معروف عامل پرت محلی\LTRfootnote{Local Outlier Factor} است. در این روش میانگین فاصله هر نقطه از همسایگان محلی محاسبه شده و اگر این میانگین از یک مقدار آستانه بیشتر باشد،‌داده به عنوان داده ناهنجار شناخته می‌شود. برای سادگی کار، میانگین فاصله نقطه تا تمام همسایگان را بر میانگین فاصله میان همسایگان نقطه محاسبه شده و مقدار آستان برابر با عدد یک درنظر گرفته می‌شود~\cite{10.1145/342009.335388}. در استفاده از این روش نیز نیازی به وجود برچسب دادگان نیست همچنین این روش پارامتری برای یادگیری ندارد و در دسته روش‌های بدون پارامتر نیز قرار می‌گیرد. در واقع این گونه روش‌ها معمولا به صورت بدون ناظر هستند.


	\begin{figure}[!h]
	\begin{center}
		\includegraphics[width=0.5\linewidth]{./images/figures/lof.png}
	\end{center}
	\caption{نمایش کلی روش عامل پرت محلی~\cite{10.1145/342009.335388}}
	\label{fig:lof}
	\centering
\end{figure}



\section{روش‌های مبتنی بر مدل آماری}
ایده اصلی در این دسته از رویکرد‌ها بدین صورت است که، دادگان عادی همواره احتمال رخدادن بالایی دارند، در نتیجه در نواحی از مدل مدل آماری قرار می‌گیرند که احتمال وقوع آنها بیشتر است. برای مثال در روش مدل خطی پویا\LTRfootnote{Dynamic liner model} ابتدا دادگان را از فضای ورودی به یک فضای از پیش تعیین شده نگاشت می‌کنیم. سپس با استفاده از مدل بدست آمده سعی در پیشبینی مقدار ورودی با توجه به دیگر دادگان موجود می‌کنیم. در اینجا امتیاز ناهنجاری میزان تفاوت مقدار پیشبینی شده و مقدار حقیقی داده است. اگر مقدار اختلاف از یک مقدار آستانه از پیش تعیین شده، که با استفاده از آزمایش با دادگان برچسب خورده بدست آمده، بیشتر باشد، به دسته دادگان ناهنجار تعلق می‌گیرد.


	\chapter{روش‌های مبتنی بر یادگیری عمیق}
	قبل از معرفی روش‌هایی که از یادگیری عمیق استفاده می‌کنند،‌ ابتدا به معرفی مدل‌های پایه‌ای یادگیری عمیق خواهیم پرداخت که در تشخیص ناهنجاری مورد استفاده قرار می‌گیرند.
	\section{}
	\section{مقایسه و نتیجه گیری}
	%-------------- Chapter 4--------------
	\chapter{نتیجه گیری و کار‌های آینده}
	\section{نتیجه گیری}
	\section{مسائل باز و کارهای قابل انجام}
	\section{موضوع پیشنهادی برای پایان نامه}
	
	
	\newpage
%دستوری برای ظاهر شدن کلمه«مراجع» در فهرست مطالب
\addcontentsline{toc}{section}{مراجع}
%ایجاد «مراجع»
\bibliographystyle{plain-fa}
\bibliography{bibliography.bib}


%\addcontentsline{toc}{section}{نمایه}
%دستوری برای ظاهر شدن کلمه «نمایه» در فهرست مطالب(البته در صورتی که از بسته‌ای که در ابتدا گفته شد استفاده نکرده باشید)
%ایجاد «نمایه»
\printindex
\newpage
\begin{latin}
\chapter*{Abstract}
Anomaly detection is a well studied problem in varios fileds of sciance.
% صفحه آخر ترجمه انگلیسی جلد

\newpage
\thispagestyle{empty}

	\vspace*{25mm}
	\centerline{\includegraphics[height=4cm]{./images/logos/iust.png}}

	\begin{center}
	\textbf{
Departmant of computer engineering
	}
	\\[1cm]
	\baselineskip=2cm
	{\titr
	\begin{Huge}
	Deep learning for anomaly detection\\[1cm]
	\end{Huge}}
	{\Large 
		\textbf{
			Master seminar report \\
Computer engineering - Artificial intelligence and robotics
		} \\[1cm]
	}

	{\Large { Student name:}
	\\
	{\Large  Ali Naderi Parizi}
	\\[.5cm]
	{\Large  Professor:}
	\\
	{\Large Dr.  Mohsen Soryani}
	\\[.6cm]
	}
April 2022
	\end{center}

\end{latin}
\end{document}
